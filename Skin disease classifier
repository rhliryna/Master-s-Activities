{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhliryna/Master-s-Activities/blob/main/Skin%20disease%20classifier\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3MuzXQUKVY5",
        "outputId": "68c9f814-899f-403e-f219-10604b2afc63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted train.zip\n",
            "Extracted valid.zip\n",
            "Extracted test.zip\n",
            "Contents of /content/: ['.config', 'train', 'valid', 'drive', 'test', 'sample_data']\n",
            "Copied train to Drive\n",
            "Copied valid to Drive\n",
            "Copied test to Drive\n",
            "Loading and preparing data...\n",
            "Found 4000 images belonging to 4 classes.\n",
            "Found 300 images belonging to 4 classes.\n",
            "Found 1200 images belonging to 4 classes.\n",
            "Found 4000 training samples\n",
            "Found 300 validation samples\n",
            "Found 1200 test samples\n",
            "Classes: ['melanoma', 'nevus', 'seborrheic_keratosis', 'train']\n",
            "\n",
            "=== Starting Model Training and Evaluation ===\n",
            "\n",
            "Training Basic CNN (LR=0.001)...\n",
            "\n",
            "Basic CNN (LR=0.001) Architecture:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,368</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │      \u001b[38;5;34m25,690,368\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,785,793</span> (98.36 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,785,793\u001b[0m (98.36 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,784,833</span> (98.36 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,784,833\u001b[0m (98.36 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.2469 - auc: 0.5239 - loss: 0.3825 - precision: 0.9090 - recall: 0.5985 "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0, MobileNetV2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Creating directories\n",
        "os.makedirs('/content/drive/MyDrive', exist_ok=True)\n",
        "drive_path = '/content/drive/MyDrive'\n",
        "model_save_path = os.path.join(drive_path, 'saved_models')\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "\n",
        "# Extracting zip files if they exist\n",
        "zip_files = [\"train.zip\", \"valid.zip\", \"test.zip\"]\n",
        "extract_path = \"/content/\"\n",
        "\n",
        "for zip_file in zip_files:\n",
        "    zip_path = os.path.join(drive_path, zip_file)\n",
        "    if os.path.exists(zip_path):\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(f\"Extracted {zip_file}\")\n",
        "    else:\n",
        "        print(f\"{zip_file} not found! Continuing without it.\")\n",
        "\n",
        "# Checking what's been extracted\n",
        "print(\"Contents of /content/:\", os.listdir(\"/content/\"))\n",
        "\n",
        "# Copy extracted directories to Drive if they exist in content\n",
        "for directory in ['train', 'valid', 'test']:\n",
        "    if os.path.exists(f\"/content/{directory}\"):\n",
        "        os.system(f\"cp -r /content/{directory} '{drive_path}/{directory}'\")\n",
        "        print(f\"Copied {directory} to Drive\")\n",
        "\n",
        "# Parameters\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50  # More epochs with early stopping for thorough training\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Defining data generators based on the directory structure\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Only rescaling for validation/test data\n",
        "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Loading data from separate directories\n",
        "print(\"Loading and preparing data...\")\n",
        "\n",
        "# Defining paths for train, validation and test\n",
        "train_dir = os.path.join(drive_path, 'train')\n",
        "valid_dir = os.path.join(drive_path, 'valid')\n",
        "test_dir = os.path.join(drive_path, 'test')\n",
        "\n",
        "# Checking if directories exist and load data\n",
        "try:\n",
        "    # Checking and load training data\n",
        "    if not os.path.exists(train_dir):\n",
        "        raise FileNotFoundError(f\"Training directory not found: {train_dir}\")\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        seed=RANDOM_SEED\n",
        "    )\n",
        "\n",
        "    # Checking and load validation data\n",
        "    if not os.path.exists(valid_dir):\n",
        "        print(f\"Validation directory not found: {valid_dir}\")\n",
        "        print(\"Will use a portion of training data for validation\")\n",
        "        train_datagen_with_split = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            validation_split=0.2\n",
        "        )\n",
        "\n",
        "        train_generator = train_datagen_with_split.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=IMG_SIZE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            class_mode='binary',\n",
        "            subset='training',\n",
        "            seed=RANDOM_SEED\n",
        "        )\n",
        "\n",
        "        validation_generator = train_datagen_with_split.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=IMG_SIZE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            class_mode='binary',\n",
        "            subset='validation',\n",
        "            seed=RANDOM_SEED\n",
        "        )\n",
        "    else:\n",
        "        validation_generator = valid_test_datagen.flow_from_directory(\n",
        "            valid_dir,\n",
        "            target_size=IMG_SIZE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            class_mode='binary',\n",
        "            shuffle=False,\n",
        "            seed=RANDOM_SEED\n",
        "        )\n",
        "\n",
        "    # Checking and loading test data\n",
        "    if not os.path.exists(test_dir):\n",
        "        print(f\"Test directory not found: {test_dir}\")\n",
        "        print(\"Will use validation data for testing\")\n",
        "        test_generator = validation_generator\n",
        "    else:\n",
        "        test_generator = valid_test_datagen.flow_from_directory(\n",
        "            test_dir,\n",
        "            target_size=IMG_SIZE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            class_mode='binary',\n",
        "            shuffle=False,\n",
        "            seed=RANDOM_SEED\n",
        "        )\n",
        "\n",
        "    print(f\"Found {train_generator.samples} training samples\")\n",
        "    print(f\"Found {validation_generator.samples} validation samples\")\n",
        "    print(f\"Found {test_generator.samples} test samples\")\n",
        "\n",
        "    # Getting class names\n",
        "    class_names = list(train_generator.class_indices.keys())\n",
        "    print(f\"Classes: {class_names}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Defining improved model architectures\n",
        "def create_basic_cnn(input_shape):\n",
        "    \"\"\"Basic CNN model with appropriate regularization\"\"\"\n",
        "    model = models.Sequential([\n",
        "        tf.keras.layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def create_efficient_net_model(input_shape):\n",
        "    \"\"\"EfficientNet transfer learning model\"\"\"\n",
        "    base_model = EfficientNetB0(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Fine-tuning the last few layers\n",
        "    for layer in base_model.layers[:-20]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = models.Sequential([\n",
        "        tf.keras.layers.Input(shape=input_shape),\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def create_mobile_net_model(input_shape):\n",
        "    \"\"\"MobileNetV2 transfer learning model with fine-tuning\"\"\"\n",
        "    base_model = MobileNetV2(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Fine-tunning the last few layers\n",
        "    for layer in base_model.layers[:-30]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = models.Sequential([\n",
        "        tf.keras.layers.Input(shape=input_shape),\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Creating model builders dictionary\n",
        "model_builders = {\n",
        "    \"Basic CNN\": create_basic_cnn,\n",
        "    \"EfficientNet\": create_efficient_net_model,\n",
        "    \"MobileNetV2\": create_mobile_net_model\n",
        "}\n",
        "\n",
        "# Defining callbacks for training\n",
        "def get_callbacks(model_name, learning_rate):\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    model_filename = f\"{model_name}_lr{learning_rate}_{timestamp}.h5\"\n",
        "    checkpoint_path = os.path.join(model_save_path, model_filename)\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            checkpoint_path,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=5,\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    return callbacks\n",
        "\n",
        "# Plot training history\n",
        "def plot_history(history, model_name):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    ax1.plot(history.history['accuracy'])\n",
        "    ax1.plot(history.history['val_accuracy'])\n",
        "    ax1.set_title(f'{model_name} - Accuracy')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.legend(['Train', 'Validation'], loc='upper left')\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot loss\n",
        "    ax2.plot(history.history['loss'])\n",
        "    ax2.plot(history.history['val_loss'])\n",
        "    ax2.set_title(f'{model_name} - Loss')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.legend(['Train', 'Validation'], loc='upper left')\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(model_save_path, f\"{model_name.replace(' ', '_')}_training_history.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Plot ROC curve\n",
        "def plot_roc_curve(y_true, y_pred_prob, model_name):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_name} - ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(model_save_path, f\"{model_name.replace(' ', '_')}_roc_curve.png\"))\n",
        "    plt.show()\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(cm, class_names, model_name):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    #Text annotations\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                    horizontalalignment=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.savefig(os.path.join(model_save_path, f\"{model_name.replace(' ', '_')}_confusion_matrix.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Evaluating model thoroughly\n",
        "def evaluate_model(model, generator, model_name):\n",
        "    # Getting predictions\n",
        "    y_true = generator.classes\n",
        "    steps = np.ceil(generator.samples / generator.batch_size)\n",
        "\n",
        "    # Using predict_generator to avoid memory issues with large datasets\n",
        "    y_pred_prob = model.predict(generator, steps=steps, verbose=1)\n",
        "    y_pred_prob = y_pred_prob.flatten()  # Ensure it's flattened\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "    # Calculating metrics\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    roc_auc = plot_roc_curve(y_true, y_pred_prob, model_name)\n",
        "\n",
        "    # Extracting values from confusion matrix\n",
        "    if cm.shape == (2, 2):  # Binary classification\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    else:\n",
        "        specificity = 'N/A'\n",
        "\n",
        "    # Displaying results\n",
        "    print(f\"\\n--- {model_name} Evaluation Results ---\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "    print(f\"Specificity: {specificity:.4f}\" if specificity != 'N/A' else f\"Specificity: {specificity}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "    # Plotting confusion matrix\n",
        "    plot_confusion_matrix(cm, class_names, model_name)\n",
        "\n",
        "    # Returning metrics as dictionary\n",
        "    metrics = {\n",
        "        'model_name': model_name,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'specificity': specificity if specificity != 'N/A' else np.nan,\n",
        "        'f1_score': f1,\n",
        "        'roc_auc': roc_auc\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Hyperparameter grid with a wider range for better performance\n",
        "learning_rates = [1e-3, 5e-4, 1e-4]\n",
        "\n",
        "# Tracking model performance\n",
        "results = []\n",
        "\n",
        "# Loop through models and learning rates\n",
        "print(\"\\n=== Starting Model Training and Evaluation ===\")\n",
        "best_model = None\n",
        "best_metrics = None\n",
        "best_auc = -1  # Initialize with a value lower than any possible AUC\n",
        "\n",
        "for model_name, model_builder in model_builders.items():\n",
        "    for lr in learning_rates:\n",
        "        full_model_name = f\"{model_name} (LR={lr})\"\n",
        "        print(f\"\\nTraining {full_model_name}...\")\n",
        "\n",
        "        # Creating model\n",
        "        input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
        "        model = model_builder(input_shape)\n",
        "\n",
        "        # Compiling model with appropriate loss and metrics\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=lr),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=[\n",
        "                'accuracy',\n",
        "                tf.keras.metrics.AUC(name='auc'),\n",
        "                tf.keras.metrics.Precision(name='precision'),\n",
        "                tf.keras.metrics.Recall(name='recall')\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Print model summary\n",
        "        print(f\"\\n{full_model_name} Architecture:\")\n",
        "        model.summary()\n",
        "\n",
        "        # Model with callbacks\n",
        "        history = model.fit(\n",
        "            train_generator,\n",
        "            epochs=EPOCHS,\n",
        "            validation_data=validation_generator,\n",
        "            callbacks=get_callbacks(model_name.replace(\" \", \"_\"), lr),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Training history\n",
        "        plot_history(history, full_model_name)\n",
        "\n",
        "        # Evaluating model\n",
        "        print(f\"\\nEvaluating {full_model_name} on test data...\")\n",
        "        metrics = evaluate_model(model, test_generator, full_model_name)\n",
        "        results.append(metrics)\n",
        "\n",
        "        # Checking if this is the best model based on AUC\n",
        "        if metrics['roc_auc'] > best_auc:\n",
        "            best_auc = metrics['roc_auc']\n",
        "            best_model = model\n",
        "            best_metrics = metrics\n",
        "            best_model_name = full_model_name\n",
        "\n",
        "            # Saving the best model\n",
        "            best_model_path = os.path.join(model_save_path, f\"best_model_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}.h5\")\n",
        "            best_model.save(best_model_path)\n",
        "            print(f\"New best model saved to {best_model_path}\")\n",
        "\n",
        "# Converting results to DataFrame for easy comparison\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n=== Performance Comparison of All Models ===\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Saving results to CSV\n",
        "results_csv_path = os.path.join(model_save_path, \"model_comparison_results.csv\")\n",
        "results_df.to_csv(results_csv_path, index=False)\n",
        "print(f\"Results saved to {results_csv_path}\")\n",
        "\n",
        "# Displaying best model information\n",
        "print(f\"\\n=== Best Model: {best_model_name} ===\")\n",
        "print(f\"Best AUC: {best_auc:.4f}\")\n",
        "print(f\"All metrics for best model:\")\n",
        "for metric, value in best_metrics.items():\n",
        "    if metric != 'model_name':\n",
        "        print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Final evaluation of best model with more detailed metrics\n",
        "print(\"\\n=== Final Evaluation of Best Model ===\")\n",
        "best_model.evaluate(test_generator, verbose=1)\n",
        "\n",
        "# Saving model architecture diagram if pydot is available\n",
        "try:\n",
        "    from tensorflow.keras.utils import plot_model\n",
        "    plot_model_path = os.path.join(model_save_path, f\"best_model_architecture.png\")\n",
        "    plot_model(best_model, to_file=plot_model_path, show_shapes=True, show_layer_names=True)\n",
        "    print(f\"Model architecture diagram saved to {plot_model_path}\")\n",
        "except ImportError:\n",
        "    print(\"Could not generate model architecture diagram. Install pydot and graphviz for this feature.\")\n",
        "\n",
        "# Print conclusion\n",
        "print(\"\\n=== Model Training Complete ===\")\n",
        "print(f\"Best model is {best_model_name} with AUC of {best_auc:.4f}\")\n",
        "print(f\"Best model and all training artifacts saved to {model_save_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWa1GfUvxTss6GQkx9gNSJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}